{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Programming_LAB.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGz9p+Zp6B1ltkVI+Vq+gp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aryabhatt-O/Mohanbugan/blob/main/Programming_LAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCPCvL_cUxSW"
      },
      "source": [
        "!pip install ipython-autotime\r\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQBteirHarqy"
      },
      "source": [
        "import requests\r\n",
        "result = requests.get('http://www.gutenberg.org/files/1524/1524-0.txt')\r\n",
        "str = result.text\r\n",
        "\r\n",
        "from nltk.tokenize import word_tokenize # using NLTK(word_tokenize)\r\n",
        "\r\n",
        "def showTokens(str):# function for showing Tokens\r\n",
        "  str_list = str.split() # splitted by space\r\n",
        "  unique_words = set(str_list) # to avoid duplicacy set()\r\n",
        "  print(\"Tokens\",unique_words)\r\n",
        "  \r\n",
        "def showTokeNs(str):\r\n",
        "  print(\"Tokens\",set(word_tokenize(str))) # to avoid duplicacy set()\r\n",
        "\r\n",
        "\r\n",
        "def showfreq(str):# function for showing occurence\r\n",
        "  str_list = str.split()\r\n",
        "  freq = {i:str_list.count(i) for i in str_list} # lambda and count()\r\n",
        "  print('occurence of  words:',freq) \r\n",
        "\r\n",
        "def showpunc(str):#function to show punctuation\r\n",
        "  import string # using standard library function\r\n",
        "  for i in str:\r\n",
        "    if i in string.punctuation:\r\n",
        "      print(\"Punctuation:\",i)\r\n",
        "\r\n",
        "def showpunc1(str):#function to show punctuation without using library function\r\n",
        "  Punctuation = []\r\n",
        "  punctuation = '''!@#$%^&*(){}[]|._-`/?:;\"'\\,~''';\r\n",
        "  for i in set(word_tokenize(str)):\r\n",
        "    if i in punctuation:\r\n",
        "      Punctuation.append(i)\r\n",
        "  print(\"Punctuation:\",Punctuation)\r\n",
        "\r\n",
        "def shownumber(str):#function to show numberlist\r\n",
        "  array =[]\r\n",
        "  for i in set(word_tokenize(str)):\r\n",
        "    if i.isdigit() == True:\r\n",
        "      array.append(i)\r\n",
        "      array1 = sorted(array)\r\n",
        "  array1.sort(key=len)\r\n",
        "  print(\"Numbers: \",array1)\r\n",
        "\r\n",
        "\r\n",
        "def showalphanumeric(str):#function to show alphanumeric\r\n",
        "  Alphanumeric = []\r\n",
        "  # str_list = str.split()\r\n",
        "  for i in set(word_tokenize(str)) :\r\n",
        "    if i.isalpha() == False and i.isnumeric() == False and i.isalnum() == True:\r\n",
        "      Alphanumeric.append(i)\r\n",
        "  print(\"Alphanumeric:\",Alphanumeric)\r\n",
        "\r\n",
        "def diganta_sir_1st_class(showTokens,showfreq,showpunc1,shownumber,showalphanumeric): # passing all functions as a parameter to the ultimate function\r\n",
        "  return (showTokeNs(str),showfreq(str),showpunc1(str),shownumber(str),showalphanumeric(str))\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "  diganta_sir_1st_class(showTokens,showfreq,showpunc1,shownumber,showalphanumeric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG6IOp705VGQ"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEfa952UlNth"
      },
      "source": [
        "main() –Outermost function of forming an input stream that recognizes the text file(front.in) and executing the entire code. If there is no loaded file (Null), the error message (\"ERROR - cannot open front.in \\n\") will be displayed through stdout. It is implemented to continue calling the key method, the lex() function, until the token reaches the EOF.\r\n",
        "\r\n",
        "lookup() – Implemented in a format that finds through which character-type factors it receives correspond to through a switch sentence. This is a format in which characters that are not Digit and Letter are filtered out of the flex() function and then classified, If one wants to add another character later, it can be easily implemented by adding case sentence.\r\n",
        "\r\n",
        "addChar() – Function that makes words by adding recognized character variables to words.\r\n",
        "\r\n",
        "getChar() – Function that determines a character class by reading one character from a file and classifying whether it is an alphabet, a number, or something else. Determined variables affect global variables, allowing reference within other functions. \r\n",
        "\r\n",
        "getNonBlank() – Function that handles gaps.\r\n",
        "\r\n",
        "lex() – As a function of key algorithms in the vocabulary analyzer, it starts by initializing the length of the lexeme.(This is the preparation to accept the new lexeme.) First, categorize by character class in switch sentence.\r\n",
        "\r\n",
        "If a word is categorized as a letter (LETTER), accept the word until the end and check that if it is a reserved word. In this task, it did not prepare a separate function to check the reservation language, but if there are more number of reserved words, it would be better to separate and make them a function for future modification.\r\n",
        "\r\n",
        "If classified as Digit (DIGIT), it accepts the digit to the end and return it as an int token.\r\n",
        "\r\n",
        "If classified as UNKNOWN, it sends the character type data to the lookup function described above and recognizes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjeZQ_ZwF2k0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evK2jVt65NDr"
      },
      "source": [
        "# file_name = \"input.txt\"\r\n",
        "# inputContent = uploaded[file_name].decode(\"utf-8\")\r\n",
        "inputContent = \"a + b^**2 = c\"\r\n",
        "fileIndex=0\r\n",
        "EOF = \"EOF\"\r\n",
        "INVALID = \"INVALID\"\r\n",
        "\r\n",
        "#Character classes\r\n",
        "LETTER = 0\r\n",
        "DIGIT = 1\r\n",
        "UNKNOWN = 99\r\n",
        "\r\n",
        "#Token codes\r\n",
        "Equal2_OP = 9 \r\n",
        "Any_Num = 10\r\n",
        "IDENT = 11\r\n",
        "ADD_OP = 21\r\n",
        "SUB_OP = 22\r\n",
        "MULT_OP = 23\r\n",
        "DIV_OP = 24\r\n",
        "LEFT_PAREN = 25\r\n",
        "RIGHT_PAREN = 26\r\n",
        "FOR_CODE = 40\r\n",
        "IF_CODE = 41\r\n",
        "ELSE_CODE = 42\r\n",
        "WHILE_CODE = 43\r\n",
        "DO_CODE = 44\r\n",
        "INT_CODE = 45\r\n",
        "FLOAT_CODE = 46\r\n",
        "SWITCH_CODE = 47\r\n",
        "\r\n",
        "lexeme = \"\"\r\n",
        "lexLen = 0\r\n",
        "\r\n",
        "def lookupSymbol(character):\r\n",
        "    if (character == \"(\"):\r\n",
        "        nextToken = LEFT_PAREN\r\n",
        "    elif (character == \")\"):\r\n",
        "        nextToken = RIGHT_PAREN\r\n",
        "    elif (character == \"+\"):\r\n",
        "        nextToken = ADD_OP\r\n",
        "    elif (character == \"-\"):\r\n",
        "        nextToken = SUB_OP\r\n",
        "    elif (character == \"*\"):\r\n",
        "        nextToken = MULT_OP\r\n",
        "    elif (character == \"/\"):\r\n",
        "        nextToken = DIV_OP\r\n",
        "    elif (character == \"=\"):\r\n",
        "      nextToken = Equal2_OP\r\n",
        "    else:\r\n",
        "        nextToken = INVALID\r\n",
        "    \r\n",
        "    return nextToken\r\n",
        "\r\n",
        "\r\n",
        "def getChar():\r\n",
        "    global inputContent\r\n",
        "    global fileIndex\r\n",
        "    if (fileIndex < len(inputContent)):\r\n",
        "        nextChar = inputContent[fileIndex]\r\n",
        "        fileIndex+=1\r\n",
        "        return nextChar\r\n",
        "    else:\r\n",
        "        return EOF\r\n",
        "    \r\n",
        "\r\n",
        "def getNonBlank():\r\n",
        "    char = getChar()\r\n",
        "    while (char.isspace()): \r\n",
        "        char = getChar()\r\n",
        "    return char\r\n",
        "\r\n",
        "def getCharClass(char):\r\n",
        "    if char.isalpha():\r\n",
        "        charClass = LETTER\r\n",
        "    elif char.isdigit():\r\n",
        "        charClass = DIGIT\r\n",
        "    else:\r\n",
        "        charClass = UNKNOWN\r\n",
        "    return charClass\r\n",
        "\r\n",
        "def lex(char):\r\n",
        "    lexeme = \"\"\r\n",
        "    charClass = getCharClass(char)\r\n",
        "    global fileIndex\r\n",
        "\r\n",
        "    if (charClass == LETTER):\r\n",
        "        lexeme+=char\r\n",
        "        nextChar = getChar()\r\n",
        "        while(nextChar != EOF and nextChar != \" \" and (getCharClass(nextChar) == LETTER or getCharClass(nextChar) == DIGIT)):\r\n",
        "            lexeme+=nextChar\r\n",
        "            nextChar = getChar()\r\n",
        "        \r\n",
        "        # Check for keywords\r\n",
        "        if (lexeme == \"if\"):\r\n",
        "            nextToken = IF_CODE\r\n",
        "        elif (lexeme == \"for\"):\r\n",
        "            nextToken = FOR_CODE\r\n",
        "        elif (lexeme == \"else\"):\r\n",
        "            nextToken = ELSE_CODE\r\n",
        "        elif (lexeme == \"while\"):\r\n",
        "            nextToken = WHILE_CODE\r\n",
        "        elif (lexeme == \"do\"):\r\n",
        "            nextToken = DO_CODE\r\n",
        "        elif (lexeme == \"int\"):\r\n",
        "            nextToken = INT_CODE\r\n",
        "        elif (lexeme == \"float\"):\r\n",
        "            nextToken = FLOAT_CODE\r\n",
        "        elif (lexeme == \"switch\"):\r\n",
        "            nextToken = SWITCH_CODE\r\n",
        "        else:\r\n",
        "            nextToken = IDENT\r\n",
        "\r\n",
        "        if nextChar != \" \" and nextChar != EOF:\r\n",
        "            fileIndex -= 1\r\n",
        "\r\n",
        "    elif (charClass == DIGIT):\r\n",
        "        lexeme+=char\r\n",
        "        nextChar = getChar()\r\n",
        "        while( (nextChar != EOF) and (nextChar != \" \") and (getCharClass(nextChar) == DIGIT) ):\r\n",
        "            lexeme+=nextChar\r\n",
        "            nextChar = getChar()\r\n",
        "        nextToken = Any_Num\r\n",
        "        if nextChar != \" \" and nextChar != EOF:\r\n",
        "            fileIndex -= 1\r\n",
        "\r\n",
        "    elif (charClass == UNKNOWN):\r\n",
        "        token = lookupSymbol(char)\r\n",
        "        lexeme+=char\r\n",
        "        nextToken = token\r\n",
        "\r\n",
        "    print (\"This token is at:\", nextToken, \" and the token is: \", lexeme)\r\n",
        "    return nextToken\r\n",
        "\r\n",
        "\r\n",
        "def main():\r\n",
        "    nextChar = getNonBlank()\r\n",
        "    if (nextChar == EOF):\r\n",
        "        print (\"File is empty\")\r\n",
        "        return\r\n",
        "\r\n",
        "    while nextChar != EOF:\r\n",
        "        nextToken = lex(nextChar)\r\n",
        "        if (nextToken == INVALID):\r\n",
        "            break\r\n",
        "        nextChar = getNonBlank()\r\n",
        "\r\n",
        "main()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5q0JVz_Lnok"
      },
 
